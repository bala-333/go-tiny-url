package main

import (
	"go/ast"
	"go/parser"
	"go/token"
	"log"
)

func main() {
	fset := token.NewFileSet() // Track file positions
	code := `
package main

func main() {
	x := 42
	_ = x // Example code
}`
	
	// Parse code into AST
	node, err := parser.ParseFile(fset, "example.go", code, parser.ParseComments)
	if err != nil {
		log.Fatal(err)
	}
	// Traverse and analyze the AST here
}

///
ast.Inspect(node, func(n ast.Node) bool {
	switch x := n.(type) {
	case *ast.AssignStmt:
		for _, lhs := range x.Lhs {
			// Check if assignment uses blank identifier '_'
			if ident, ok := lhs.(*ast.Ident); ok && ident.Name == "_" {
				pos := fset.Position(ident.Pos())
				log.Printf("Assignment to blank identifier at %s", pos)
			}
		}
	}
	return true // Continue traversal
})

//
var currentLoop ast.Node // Track if inside a loop

ast.Inspect(node, func(n ast.Node) bool {
	switch x := n.(type) {
	case *ast.ForStmt, *ast.RangeStmt:
		// Entering a loop
		currentLoop = n
		defer func() { currentLoop = nil }() // Reset after traversal
	case *ast.DeferStmt:
		if currentLoop != nil {
			pos := fset.Position(x.Defer)
			log.Printf("Defer inside loop at %s", pos)
		}
	}
	return true
})

///
import (
	"go/types"
	"golang.org/x/tools/go/loader"
)

// Load and type-check a package
func loadPackage() {
	var conf loader.Config
	conf.Import("example.com/your/package")
	prog, err := conf.Load()
	if err != nil {
		log.Fatal(err)
	}
	pkg := prog.Package("example.com/your/package")
	// Use pkg.Types to access type information
}

func checkUnusedVars(node *ast.File, fset *token.FileSet) {
	used := make(map[*ast.Object]bool)
	declared := make(map[*ast.Object]bool)

	// Collect declared variables
	ast.Inspect(node, func(n ast.Node) bool {
		switch x := n.(type) {
		case *ast.Ident:
			if x.Obj != nil && x.Obj.Kind == ast.Var {
				if x.Obj.Decl != nil {
					declared[x.Obj] = true
				}
				used[x.Obj] = true // Mark as used
			}
		}
		return true
	})

	// Report unused variables
	for obj := range declared {
		if !used[obj] {
			pos := fset.Position(obj.Pos())
			log.Printf("Unused variable '%s' at %s", obj.Name, pos)
		}
	}
}	


analyzer/
├── core/             # Framework logic
│   ├── rule_engine.go
│   └── reporter.go
├── languages/        # Language-specific plugins
│   ├── go/
│   ├── python/
│   └── javascript/
└── rules/            # Cross-language/custom rules



type Rule interface {
    Analyze(ast interface{}) []Issue
    ID() string
    Severity() string
}
func DetectHardcodedSecrets(code string) []Issue {
    // Regex for AWS keys, passwords, etc.
}


analyzer/
├── core/
│   ├── analyzer.go      # Core analysis workflow
│   └── types.go         # Shared interfaces/types
├── languages/
│   ├── go/
│   │   ├── parser.go    # Go-specific parser
│   │   └── rules.go     # Go-specific rules
│   └── python/
│       ├── parser.go    # Python-specific parser
│       └── rules.go     # Python-specific rules
└── main.go              # CLI entrypoint


package core

// Language defines a programming language plugin
type Language interface {
	Name() string
	Parse(filePath string) (interface{}, error) // Returns language-specific AST
	SupportedExtensions() []string
}

// Rule defines a static analysis rule
type Rule interface {
	ID() string
	Analyze(ast interface{}, lang Language) []Issue
	Severity() string // "error", "warning", "info"
}

// Issue represents a detected problem
type Issue struct {
	RuleID     string `json:"rule_id"`
	Message    string `json:"message"`
	Severity   string `json:"severity"`
	Line       int    `json:"line"`
	Column     int    `json:"column"`
	FilePath   string `json:"file_path"`
}


package core

import (
	"path/filepath"
)

// Analyzer coordinates parsing and analysis
type Analyzer struct {
	languages map[string]Language
	rules     []Rule
}

func NewAnalyzer() *Analyzer {
	return &Analyzer{
		languages: make(map[string]Language),
		rules:     []Rule{},
	}
}

func (a *Analyzer) RegisterLanguage(lang Language) {
	for _, ext := range lang.SupportedExtensions() {
		a.languages[ext] = lang
	}
}

func (a *Analyzer) RegisterRule(rule Rule) {
	a.rules = append(a.rules, rule)
}

func (a *Analyzer) ProcessFile(filePath string) ([]Issue, error) {
	ext := filepath.Ext(filePath)
	lang, exists := a.languages[ext]
	if !exists {
		return nil, nil // Skip unsupported files
	}

	ast, err := lang.Parse(filePath)
	if err != nil {
		return nil, err
	}

	var issues []Issue
	for _, rule := range a.rules {
		ruleIssues := rule.Analyze(ast, lang)
		issues = append(issues, ruleIssues...)
	}

	return issues, nil
}

package go_lang

import (
	"go/ast"
	"go/parser"
	"go/token"
)

type GoLanguage struct{}

func (g *GoLanguage) Name() string {
	return "go"
}

func (g *GoLanguage) SupportedExtensions() []string {
	return []string{".go"}
}

func (g *GoLanguage) Parse(filePath string) (interface{}, error) {
	fset := token.NewFileSet()
	node, err := parser.ParseFile(fset, filePath, nil, parser.AllErrors)
	if err != nil {
		return nil, err
	}
	return struct {
		AST  *ast.File
		Fset *token.FileSet
	}{node, fset}, nil
}

package go_lang

import (
	"go/ast"
	"strings"

	"analyzer/core"
)

type TodoCommentRule struct{}

func (r *TodoCommentRule) ID() string         { return "GO-001" }
func (r *TodoCommentRule) Severity() string   { return "warning" }

func (r *TodoCommentRule) Analyze(rawAST interface{}, lang core.Language) []core.Issue {
	goAST := rawAST.(struct {
		AST  *ast.File
		Fset *token.FileSet
	})

	var issues []core.Issue
	for _, comment := range goAST.AST.Comments {
		if strings.Contains(comment.Text(), "TODO") {
			pos := goAST.Fset.Position(comment.Pos())
			issues = append(issues, core.Issue{
				RuleID:   r.ID(),
				Message:  "TODO comment found",
				Severity: r.Severity(),
				Line:     pos.Line,
				Column:   pos.Column,
				FilePath: pos.Filename,
			})
		}
	}
	return issues
}

package main

import (
	"encoding/json"
	"fmt"
	"log"
	"os"

	"analyzer/core"
	go_lang "analyzer/languages/go"
)

func main() {
	analyzer := core.NewAnalyzer()
	
	// Register languages
	analyzer.RegisterLanguage(&go_lang.GoLanguage{})
	// analyzer.RegisterLanguage(&python.PythonLanguage{})
	
	// Register rules
	analyzer.RegisterRule(&go_lang.TodoCommentRule{})
	// analyzer.RegisterRule(&go_lang.UnusedVariableRule{})

	// Process files
	file := "example.go"
	issues, err := analyzer.ProcessFile(file)
	if err != nil {
		log.Fatal(err)
	}

	// Print results as JSON
	jsonOutput, _ := json.MarshalIndent(issues, "", "  ")
	fmt.Println(string(jsonOutput))
}

type UnusedVariableRule struct{}

func (r *UnusedVariableRule) ID() string       { return "GO-002" }
func (r *UnusedVariableRule) Severity() string { return "warning" }

func (r *UnusedVariableRule) Analyze(rawAST interface{}, _ core.Language) []core.Issue {
    goAST := rawAST.(struct {
        AST  *ast.File
        Fset *token.FileSet
    })
    fset := goAST.Fset

    // Track variable declarations and usages
    declared := make(map[*ast.Object]bool)
    used := make(map[*ast.Object]bool)

    ast.Inspect(goAST.AST, func(n ast.Node) bool {
        switch x := n.(type) {
        case *ast.Ident:
            if x.Obj != nil && x.Obj.Kind == ast.Var {
                if x.Obj.Decl != nil {
                    declared[x.Obj] = true // Declaration
                }
                used[x.Obj] = true // Usage
            }
        }
        return true
    })

    var issues []core.Issue
    for obj := range declared {
        if !used[obj] {
            pos := fset.Position(obj.Pos())
            issues = append(issues, core.Issue{
                RuleID:   r.ID(),
                Message:  fmt.Sprintf("Unused variable '%s'", obj.Name),
                Severity: r.Severity(),
                Line:     pos.Line,
                Column:   pos.Column,
                FilePath: pos.Filename,
            })
        }
    }
    return issues
}



type UnhandledErrorRule struct{}

func (r *UnhandledErrorRule) ID() string       { return "GO-003" }
func (r *UnhandledErrorRule) Severity() string { return "error" }

func (r *UnhandledErrorRule) Analyze(rawAST interface{}, _ core.Language) []core.Issue {
    goAST := rawAST.(struct {
        AST  *ast.File
        Fset *token.FileSet
    })
    fset := goAST.Fset

    var issues []core.Issue
    ast.Inspect(goAST.AST, func(n ast.Node) bool {
        callExpr, ok := n.(*ast.CallExpr)
        if !ok {
            return true
        }

        // Check if the function returns an error
        funcIdent, ok := callExpr.Fun.(*ast.SelectorExpr)
        if !ok {
            return true
        }

        // Simplified: Assume functions ending with "Err" return errors
        funcName := funcIdent.Sel.Name
        if strings.HasSuffix(funcName, "Err") {
            // Check if the return value is ignored
            if parent, ok := callExpr.Parent().(*ast.ExprStmt); ok && parent != nil {
                pos := fset.Position(callExpr.Pos())
                issues = append(issues, core.Issue{
                    RuleID:   r.ID(),
                    Message:  fmt.Sprintf("Unhandled error from '%s'", funcName),
                    Severity: r.Severity(),
                    Line:     pos.Line,
                    Column:   pos.Column,
                    FilePath: pos.Filename,
                })
            }
        }
        return true
    })
    return issues
}



// Assuming Python AST is parsed using a library like "github.com/google/go-python/pythonparser"
type EvalUsageRule struct{}

func (r *EvalUsageRule) ID() string       { return "PY-001" }
func (r *EvalUsageRule) Severity() string { return "error" }

func (r *EvalUsageRule) Analyze(rawAST interface{}, _ core.Language) []core.Issue {
    pyAST := rawAST.(*pythonparser.Module) // Example AST type
    var issues []core.Issue

    // Traverse AST to find eval() calls
    pythonparser.Inspect(pyAST, func(n pythonparser.Node) bool {
        call, ok := n.(*pythonparser.CallExpr)
        if !ok {
            return true
        }

        if ident, ok := call.Func.(*pythonparser.NameExpr); ok && ident.Id == "eval" {
            pos := call.Pos()
            issues = append(issues, core.Issue{
                RuleID:   r.ID(),
                Message:  "Use of unsafe eval()",
                Severity: r.Severity(),
                Line:     pos.Line,
                Column:   pos.Column,
                FilePath: pos.Filename,
            })
        }
        return true
    })
    return issues
}


type MagicNumberRule struct{}

func (r *MagicNumberRule) ID() string       { return "COMMON-001" }
func (r *MagicNumberRule) Severity() string { return "info" }

func (r *MagicNumberRule) Analyze(rawAST interface{}, lang core.Language) []core.Issue {
    var issues []core.Issue

    switch lang.Name() {
    case "go":
        goAST := rawAST.(struct {
            AST  *ast.File
            Fset *token.FileSet
        })
        ast.Inspect(goAST.AST, func(n ast.Node) bool {
            if lit, ok := n.(*ast.BasicLit); ok && lit.Kind == token.INT {
                pos := goAST.Fset.Position(lit.Pos())
                issues = append(issues, core.Issue{
                    RuleID:   r.ID(),
                    Message:  "Magic number detected",
                    Severity: r.Severity(),
                    Line:     pos.Line,
                    Column:   pos.Column,
                    FilePath: pos.Filename,
                })
            }
            return true
        })
    // Add cases for Python/other languages
    }
    return issues
}

type AssertUsageRule struct{}

func (r *AssertUsageRule) ID() string       { return "PY-002" }
func (r *AssertUsageRule) Severity() string { return "warning" }

func (r *AssertUsageRule) Analyze(rawAST interface{}, _ core.Language) []core.Issue {
    pyAST := rawAST.(*pythonparser.Module)
    var issues []core.Issue

    pythonparser.Inspect(pyAST, func(n pythonparser.Node) bool {
        stmt, ok := n.(*pythonparser.AssertStmt)
        if !ok {
            return true
        }
        pos := stmt.Pos()
        issues = append(issues, core.Issue{
            RuleID:   r.ID(),
            Message:  "Avoid assert in production code",
            Severity: r.Severity(),
            Line:     pos.Line,
            Column:   pos.Column,
            FilePath: pos.Filename,
        })
        return true
    })
    return issues
}

func main() {
    analyzer := core.NewAnalyzer()
    analyzer.RegisterLanguage(&go_lang.GoLanguage{})
    analyzer.RegisterLanguage(&python.PythonLanguage{}) // Add Python plugin

    analyzer.RegisterRule(&go_lang.TodoCommentRule{})
    analyzer.RegisterRule(&go_lang.UnusedVariableRule{})
    analyzer.RegisterRule(&go_lang.UnhandledErrorRule{})
    analyzer.RegisterRule(&go_lang.DeferInLoopRule{})
    analyzer.RegisterRule(&python.EvalUsageRule{})
    analyzer.RegisterRule(&python.AssertUsageRule{})
    analyzer.RegisterRule(&rules.MagicNumberRule{})

    // Process files...
}



[
  {
    "rule_id": "GO-002",
    "message": "Unused variable 'unusedVar'",
    "severity": "warning",
    "line": 10,
    "column": 2,
    "file_path": "example.go"
  },
  {
    "rule_id": "PY-001",
    "message": "Use of unsafe eval()",
    "severity": "error",
    "line": 5,
    "column": 4,
    "file_path": "example.py"
  }
]


package java

import (
	"github.com/smacker/go-tree-sitter"
	"github.com/smacker/go-tree-sitter/java"
)

type JavaLanguage struct{}

func (j *JavaLanguage) Name() string           { return "java" }
func (j *JavaLanguage) SupportedExtensions() []string { return []string{".java"} }

func (j *JavaLanguage) Parse(filePath string) (interface{}, error) {
	// Read file content
	code, err := os.ReadFile(filePath)
	if err != nil {
		return nil, err
	}

	// Configure Tree-sitter
	parser := sitter.NewParser()
	parser.SetLanguage(java.GetLanguage())
	tree, err := parser.ParseCtx(context.Background(), nil, code)
	if err != nil {
		return nil, err
	}

	return tree, nil
}


package java

import (
	"fmt"
	"analyzer/core"
	sitter "github.com/smacker/go-tree-sitter"
)

type SystemExitRule struct{}

func (r *SystemExitRule) ID() string       { return "JAVA-001" }
func (r *SystemExitRule) Severity() string { return "error" }

func (r *SystemExitRule) Analyze(rawAST interface{}, _ core.Language) []core.Issue {
	tree := rawAST.(*sitter.Tree)
	root := tree.RootNode()

	var issues []core.Issue
	query := `(method_invocation
                object: (identifier) @obj (#eq? @obj "System")
                name: (identifier) @name (#eq? @name "exit")
              )`

	q, _ := sitter.NewQuery([]byte(query), java.GetLanguage())
	defer q.Close()

	cursor := sitter.NewQueryCursor()
	defer cursor.Close()
	cursor.Exec(q, root)

	for {
		match, ok := cursor.NextMatch()
		if !ok {
			break
		}
		for _, cap := range match.Captures {
			pos := sitter.Point{
				Row:    cap.Node.StartPoint().Row + 1, // 1-based line
				Column: cap.Node.StartPoint().Column,
			}
			issues = append(issues, core.Issue{
				RuleID:   r.ID(),
				Message:  "Avoid System.exit() in application code",
				Severity: r.Severity(),
				Line:     int(pos.Row),
				Column:   int(pos.Column),
				FilePath: "", // Populate from context
			})
		}
	}
	return issues
}



type HashCodeEqualsRule struct{}

func (r *HashCodeEqualsRule) ID() string       { return "JAVA-002" }
func (r *HashCodeEqualsRule) Severity() string { return "warning" }

func (r *HashCodeEqualsRule) Analyze(rawAST interface{}, _ core.Language) []core.Issue {
	tree := rawAST.(*sitter.Tree)
	root := tree.RootNode()

	var issues []core.Issue
	query := `(class_declaration
                body: (class_body
                  (method_declaration
                    name: (identifier) @method_name (#eq? @method_name "equals")
                  )
                  (! (method_declaration
                    name: (identifier) @method_name (#eq? @method_name "hashCode")
                  ))
              )`

	q, _ := sitter.NewQuery([]byte(query), java.GetLanguage())
	defer q.Close()

	cursor := sitter.NewQueryCursor()
	defer cursor.Close()
	cursor.Exec(q, root)

	for {
		match, ok := cursor.NextMatch()
		if !ok {
			break
		}
		for _, cap := range match.Captures {
			if cap.Node.Type() == "class_declaration" {
				className := cap.Node.ChildByFieldName("name").Content()
				pos := sitter.Point{
					Row:    cap.Node.StartPoint().Row + 1,
					Column: cap.Node.StartPoint().Column,
				}
				issues = append(issues, core.Issue{
					RuleID:   r.ID(),
					Message:  fmt.Sprintf("Class '%s' overrides equals() but not hashCode()", className),
					Severity: r.Severity(),
					Line:     int(pos.Row),
					Column:   int(pos.Column),
					FilePath: "",
				})
			}
		}
	}
	return issues
}


type HashCodeEqualsRule struct{}

func (r *HashCodeEqualsRule) ID() string       { return "JAVA-002" }
func (r *HashCodeEqualsRule) Severity() string { return "warning" }

func (r *HashCodeEqualsRule) Analyze(rawAST interface{}, _ core.Language) []core.Issue {
	tree := rawAST.(*sitter.Tree)
	root := tree.RootNode()

	var issues []core.Issue
	query := `(class_declaration
                body: (class_body
                  (method_declaration
                    name: (identifier) @method_name (#eq? @method_name "equals")
                  )
                  (! (method_declaration
                    name: (identifier) @method_name (#eq? @method_name "hashCode")
                  ))
              )`

	q, _ := sitter.NewQuery([]byte(query), java.GetLanguage())
	defer q.Close()

	cursor := sitter.NewQueryCursor()
	defer cursor.Close()
	cursor.Exec(q, root)

	for {
		match, ok := cursor.NextMatch()
		if !ok {
			break
		}
		for _, cap := range match.Captures {
			if cap.Node.Type() == "class_declaration" {
				className := cap.Node.ChildByFieldName("name").Content()
				pos := sitter.Point{
					Row:    cap.Node.StartPoint().Row + 1,
					Column: cap.Node.StartPoint().Column,
				}
				issues = append(issues, core.Issue{
					RuleID:   r.ID(),
					Message:  fmt.Sprintf("Class '%s' overrides equals() but not hashCode()", className),
					Severity: r.Severity(),
					Line:     int(pos.Row),
					Column:   int(pos.Column),
					FilePath: "",
				})
			}
		}
	}
	return issues
}

func main() {
	analyzer := core.NewAnalyzer()
	
	// Register languages
	analyzer.RegisterLanguage(&go_lang.GoLanguage{})
	analyzer.RegisterLanguage(&java.JavaLanguage{}) // Add Java

	// Register rules
	analyzer.RegisterRule(&java.SystemExitRule{})
	analyzer.RegisterRule(&java.HashCodeEqualsRule{})
	
	// Process Java file
	issues, err := analyzer.ProcessFile("Example.java")
	// ...
}

// languages/java/rules.go
type SQLInjectionRule struct{}

func (r *SQLInjectionRule) ID() string       { return "SEC-001" }
func (r *SQLInjectionRule) Severity() string { return "critical" }

func (r *SQLInjectionRule) Analyze(rawAST interface{}, _ core.Language) []core.Issue {
	tree := rawAST.(*sitter.Tree)
	root := tree.RootNode()

	query := `(method_invocation
                object: (identifier) @obj (#match? @obj "(?i)statement")
                name: (identifier) @method (#eq? @method "executeQuery")
              )`

	var issues []core.Issue
	q, _ := sitter.NewQuery([]byte(query), java.GetLanguage())
	cursor := sitter.NewQueryCursor()
	cursor.Exec(q, root)

	for {
		match, ok := cursor.NextMatch()
		if !ok { break }
		for _, cap := range match.Captures {
			pos := cap.Node.StartPoint()
			issues = append(issues, core.Issue{
				RuleID:   r.ID(),
				Message:  "Unsafe SQL query construction with Statement",
				Severity: r.Severity(),
				Line:     int(pos.Row) + 1,
				FilePath: "", // Populate from context
			})
		}
	}
	return issues
}

// languages/go/rules.go
type GoSQLInjectionRule struct{}

func (r *GoSQLInjectionRule) Analyze(rawAST interface{}, _ core.Language) []core.Issue {
	goAST := rawAST.(struct { AST *ast.File; Fset *token.FileSet })
	var issues []core.Issue

	ast.Inspect(goAST.AST, func(n ast.Node) bool {
		call, ok := n.(*ast.CallExpr)
		if !ok { return true }

		// Check for db.Query(fmt.Sprintf(...)) or db.Query("..." + var)
		if isSQLQueryCall(call) && usesStringFormatting(call) {
			pos := goAST.Fset.Position(call.Pos())
			issues = append(issues, core.Issue{
				RuleID:   "SEC-001",
				Message:  "SQL query built with unsafe string formatting",
				Severity: "critical",
				Line:     pos.Line,
			})
		}
		return true
	})
	return issues
}

func isSQLQueryCall(call *ast.CallExpr) bool {
	if sel, ok := call.Fun.(*ast.SelectorExpr); ok {
		return strings.HasSuffix(sel.Sel.Name, "Query") // db.Query, tx.Exec
	}
	return false
}

func usesStringFormatting(call *ast.CallExpr) bool {
	// Detect fmt.Sprintf or concatenation in arguments
	for _, arg := range call.Args {
		if isSprintfCall(arg) || isConcatExpr(arg) {
			return true
		}
	}
	return false
}


// rules/secrets.go
type HardcodedSecretRule struct{}

func (r *HardcodedSecretRule) Analyze(rawAST interface{}, lang core.Language) []core.Issue {
	// Read raw file content (not just AST)
	fileContent := getFileContent(rawAST)
	var issues []core.Issue

	// Regex patterns for secrets
	patterns := map[string]string{
		"API_KEY": `(?i)api_?key\s*=\s*["'][a-f0-9]{20,}["']`,
		"PASSWORD": `(?i)password\s*=\s*["'].+["']`,
	}

	for key, regex := range patterns {
		re := regexp.MustCompile(regex)
		matches := re.FindAllStringSubmatchIndex(fileContent, -1)
		for _, m := range matches {
			issues = append(issues, core.Issue{
				RuleID:   "SEC-003",
				Message:  fmt.Sprintf("Hardcoded %s detected", key),
				Severity: "critical",
				Line:     findLineNumber(fileContent, m[0]),
			})
		}
	}
	return issues
}

///
package python

import (
    "analyzer/core"
    "github.com/go-python/gpython/ast"
)

// Custom visitor to detect eval() calls
type evalVisitor struct {
    issues   []core.Issue
    filePath string
}

// Implement ast.Visitor interface
func (v *evalVisitor) Visit(node ast.AST) bool {
    // Check if node is a function call
    call, ok := node.(*ast.Call)
    if !ok {
        return true // Continue traversal
    }

    // Check for eval() in direct calls or attributes
    switch fn := call.Func.(type) {
    case *ast.Name:
        if fn.Id == "eval" {
            v.addIssue(fn.Pos())
        }
    case *ast.Attribute:
        if fn.Attr == "eval" {
            v.addIssue(fn.Pos())
        }
    }

    return true // Continue traversal
}

// Helper to add issues
func (v *evalVisitor) addIssue(pos ast.Pos) {
    v.issues = append(v.issues, core.Issue{
        RuleID:   "PY-001",
        Message:  "eval() usage detected",
        Severity: "critical",
        Line:     pos.Line,
        Column:   pos.Column + 1, // Columns are 1-based
        FilePath: v.filePath,
    })
}

type EvalRule struct{}

func (r *EvalRule) ID() string       { return "PY-001" }
func (r *EvalRule) Severity() string { return "critical" }

func (r *EvalRule) Analyze(rawAST interface{}) []core.Issue {
    pyAST := rawAST.(*PythonAST)
    visitor := &evalVisitor{
        filePath: pyAST.FilePath,
    }
    ast.Walk(pyAST.Module, visitor)
    return visitor.issues
}

package python

import (
    "github.com/go-python/gpython/ast"
)

type PythonAST struct {
    Module   *ast.Module  // AST root node
    FilePath string       // Source file path
    Errors   []error      // Parsing errors
}


package python

// Simplified Python parser (real implementation would use a proper AST parser)
type PythonAST struct {
    Content string
}

type PythonLanguage struct{}

func (p *PythonLanguage) Name() string { return "python" }
func (p *PythonLanguage) SupportedExtensions() []string { return []string{".py"} }

func (p *PythonLanguage) Parse(filePath string) (interface{}, error) {
    content, err := os.ReadFile(filePath)
    if err != nil {
        return nil, err
    }
    return &PythonAST{Content: string(content)}, nil
}

func (p *PythonLanguage) GetRules() []core.Rule {
    return []core.Rule{
        &EvalUsageRule{},
    }
}

package python

import (
    "analyzer/core"
    "strings"
)

type EvalUsageRule struct{}

func (r *EvalUsageRule) ID() string { return "PY-001" }
func (r *EvalUsageRule) Severity() string { return "error" }

func (r *EvalUsageRule) Analyze(rawAST interface{}) []core.Issue {
    pyAST := rawAST.(*PythonAST)
    var issues []core.Issue
    
    lines := strings.Split(pyAST.Content, "\n")
    for i, line := range lines {
        if strings.Contains(line, "eval(") {
            issues = append(issues, core.Issue{
                RuleID:   r.ID(),
                Message:  "eval() usage detected",
                Severity: r.Severity(),
                Line:     i + 1,
                Column:   0,
                FilePath: "",
            })
        }
    }
    return issues
}

Static Code Analysis Tool Compatibility
Language	Tree-sitter (go-tree-sitter)	ANTLR4
Go	✅ Excellent: Native support, fast parsing, and accurate syntax trees. Ideal for linting.	⚠️ Moderate: Requires community grammar and experimental Go runtime. Limited error recovery.
JavaScript/TS	✅ Good: Real-time parsing, handles JSX/TSX. Best for IDE plugins or lightweight analysis.	✅ Strong: Mature grammar, supports semantic predicates. Better for deep control-flow analysis.
Python	✅ Good: Fast for syntax checks, but limited semantic understanding (e.g., type inference).	✅ Strong: Full grammar control. Better for building custom analyzers (e.g., security linters).
Java	✅ Basic: Syntax trees work for linting, but no built-in symbol resolution.	✅ Best: Reference implementation. Ideal for building Checkstyle-like tools or bytecode analyzers.
C/C++	⚠️ Limited: Struggles with preprocessor macros and templates. Use for syntax-only checks.	✅ Strong: Mature grammars. Use Clang-based tools for deep analysis, but ANTLR works for custom rules.
Rust	✅ Good: Official grammar. Macros partially parsed. Suitable for basic linting.	❌ Unstable: No official grammar. Avoid for Rust analysis.
C#	⚠️ Basic: Community grammar. Limited semantic support.	✅ Strong: Robust C# runtime. Integrates with Roslyn for advanced analysis.
Ruby	⚠️ Fragile: Ambiguous syntax (e.g., blocks) confuses parser. Use for simple rules.	❌ Unstable: No reliable grammar. Avoid for Ruby analysis.
PHP	⚠️ Basic: Mixed HTML/PHP parsing issues. Use for syntax checks only.	⚠️ Experimental: Slow and error-prone. Prefer PHPStan/PHPCS for analysis.
SQL	✅ Good: Official grammar. Use for syntax validation or basic injection detection.	✅ Strong: Dialect-specific grammars (e.g., PostgreSQL). Better for query optimization checks.
Kotlin	⚠️ Experimental: Community grammar. Use ANTLR4 for JVM-based analysis instead.	✅ Moderate: Use Java runtime with Kotlin interop.
Swift	⚠️ Experimental: Community grammar. Prefer Xcode’s built-in tools.	❌ Unstable: No official support.
TypeScript	✅ Good: Similar to JS. Use for IDE plugins or AST-based pattern matching.	✅ Strong: Mature grammar. Better for type-system-aware analysis.
Bash/Shell	⚠️ Basic: Struggles with expansions. Use for simple syntax checks.	⚠️ Experimental: Limited grammar. Prefer ShellCheck for analysis.
Key Considerations for Static Analysis
Feature	Tree-sitter (go-tree-sitter)	ANTLR4
Speed	✅ Blazing-fast incremental parsing. Ideal for real-time linting.	⚠️ Slower, especially in interpreted targets (Python/JS).
Syntax vs. Semantics	✅ Syntax-only analysis (e.g., linting, formatting).	✅ Full control over semantics (e.g., type checking, CFG generation).
Error Recovery	⚠️ Basic heuristics. May miss nested errors.	✅ Advanced error recovery and reporting.
Grammar Flexibility	❌ Limited to existing grammars. Hard to customize.	✅ Extendable grammars with semantic predicates.
Integration with Go	✅ Native Go bindings. Easy to embed in Go tools.	⚠️ Possible via Go runtime (experimental) or C++ interop.
Symbol Resolution	❌ Requires manual work (no built-in scope tracking).	✅ Possible with listener/visitor patterns and custom logic.
Community Grammars	✅ Official grammars for 40+ languages (e.g., JS, Rust, HTML).	✅ 100+ community grammars, but quality varies.
When to Choose Tree-sitter
Lightweight Analysis: Syntax highlighting, formatting, or simple pattern matching (e.g., finding TODO comments).

Real-Time Feedback: IDE plugins, editors, or CI tools needing fast parsing.

Go-Centric Workflows: Easy integration with Go without CGO.

When to Choose ANTLR4
Deep Semantic Analysis: Type checking, control-flow graphs, or data-flow analysis.

Custom Rules: Modify grammars to enforce project-specific patterns (e.g., security rules).

Cross-Language Tools: Generate parsers in multiple targets (e.g., Java → Python).

Recommended Pairings
Tree-sitter + Semgrep: Use Tree-sitter for AST extraction and Semgrep for pattern matching.

ANTLR4 + LLVM/Clang: For C/C++ analysis, combine ANTLR with Clang’s AST.

ANTLR4 + LSP: Build a Language Server Protocol (LSP) tool with deep semantic features.

Top Static Analysis Use Cases
Tool	Best For	Example Projects
Tree-sitter	- IDE plugins (e.g., VS Code extensions)
- Linters (e.g., ESLint-like tools)
- Code formatters	GitHub Copilot, Neovim, Tree-sitter-based linters.
ANTLR4	- Custom security scanners
- Compiler frontends
- Legacy code migration tools	Checkstyle, PMD, SQL injection detectors, transpilers.
Final Recommendation
Use Tree-sitter if:

You need speed and simplicity for syntax-driven tasks.

Your language has an official, well-maintained grammar.

Use ANTLR4 if:

You need deep semantic analysis or custom grammar rules.

You’re analyzing enterprise languages (Java, C#, SQL) or legacy systems.

For hybrid approaches, combine both: use Tree-sitter for fast syntax parsing and ANTLR4 for semantic passes. For example, extract an AST with Tree-sitter and feed it into an ANTLR-based analyzer for deeper checks.

For more details, see:

Tree-sitter Grammars

ANTLR4 Static Analysis Examples

New chat


package core

import "github.com/smacker/go-tree-sitter"

type (
    // Parser interface for language-specific parsers
    Parser interface {
        Parse([]byte) *tree_sitter.Tree
    }

    // Rule interface for analysis rules
    Rule interface {
        Detect(*tree_sitter.Tree) []Issue
    }

    // Issue represents a detected problem
    Issue struct {
        Line    int
        Column  int
        Message string
    }

    // Analyzer coordinates the analysis workflow
    Analyzer struct {
        Parser Parser
        Rules  []Rule
    }
)

package core

func NewAnalyzer(p Parser, rules []Rule) *Analyzer {
    return &Analyzer{
        Parser: p,
        Rules:  rules,
    }
}

func (a *Analyzer) Analyze(code []byte) []Issue {
    tree := a.Parser.Parse(code)
    var results []Issue
    
    for _, rule := range a.Rules {
        results = append(results, rule.Detect(tree)...)
    }
    
    return results
}


package python

import (
    "github.com/smacker/go-tree-sitter"
    "github.com/smacker/go-tree-sitter/python"
)

type Parser struct {
    parser *tree_sitter.Parser
}

func NewParser() *Parser {
    p := tree_sitter.NewParser()
    p.SetLanguage(python.GetLanguage())
    return &Parser{parser: p}
}

func (p *Parser) Parse(code []byte) *tree_sitter.Tree {
    return p.parser.Parse(nil, code)
}


package python

import (
    "github.com/smacker/go-tree-sitter"
    "analyzer/core"
)

type EvalRule struct{}

func (r EvalRule) Detect(tree *tree_sitter.Tree) []core.Issue {
    query := `(
        (call
            function: [
                (identifier) @func_id
                (parenthesized_expression (identifier) @func_id)
            ]
            arguments: (argument_list)
        ) @call
        (#eq? @func_id "eval")
    )`

    q, _ := tree_sitter.NewQuery([]byte(query), python.GetLanguage())
    defer q.Close()

    qc := tree_sitter.NewQueryCursor()
    defer qc.Close()
    qc.Exec(q, tree.RootNode())

    var issues []core.Issue
    for {
        match, ok := qc.NextMatch()
        if !ok {
            break
        }

        for _, capture := range match.Captures {
            if q.CaptureNameForId(capture.Index) == "func_id" {
                start := capture.Node.StartPoint()
                issues = append(issues, core.Issue{
                    Line:    int(start.Row) + 1,
                    Column:  int(start.Column) + 1,
                    Message: "Use of eval() is dangerous",
                })
            }
        }
    }
    return issues
}

package golang

import (
    "github.com/smacker/go-tree-sitter"
    "github.com/smacker/go-tree-sitter/golang"
)

type Parser struct {
    parser *tree_sitter.Parser
}

func NewParser() *Parser {
    p := tree_sitter.NewParser()
    p.SetLanguage(golang.GetLanguage())
    return &Parser{parser: p}
}

func (p *Parser) Parse(code []byte) *tree_sitter.Tree {
    return p.parser.Parse(nil, code)
}


package golang

import (
    "github.com/smacker/go-tree-sitter"
    "analyzer/core"
)

type UnsafeRule struct{}

func (r UnsafeRule) Detect(tree *tree_sitter.Tree) []core.Issue {
    query := `(
        (import_spec path: (string_lit) @path
        (#match? @path "\"unsafe\"")
    ) @import`

    q, _ := tree_sitter.NewQuery([]byte(query), golang.GetLanguage())
    defer q.Close()

    qc := tree_sitter.NewQueryCursor()
    defer qc.Close()
    qc.Exec(q, tree.RootNode())

    var issues []core.Issue
    for {
        match, ok := qc.NextMatch()
        if !ok {
            break
        }

        for _, capture := range match.Captures {
            if q.CaptureNameForId(capture.Index) == "import" {
                start := capture.Node.StartPoint()
                issues = append(issues, core.Issue{
                    Line:    int(start.Row) + 1,
                    Column:  int(start.Column) + 1,
                    Message: "Use of unsafe package",
                })
            }
        }
    }
    return issues
}

package main

import (
    "fmt"
    "os"
    "path/filepath"
    "analyzer/core"
    "analyzer/languages/golang"
    "analyzer/languages/python"
)

func main() {
    if len(os.Args) < 2 {
        fmt.Println("Usage: analyzer <file>")
        os.Exit(1)
    }

    filePath := os.Args[1]
    code, err := os.ReadFile(filePath)
    if err != nil {
        panic(err)
    }

    analyzer := createAnalyzer(filePath)
    issues := analyzer.Analyze(code)

    for _, issue := range issues {
        fmt.Printf("[%s:%d:%d] %s\n", filePath, issue.Line, issue.Column, issue.Message)
    }
}

func createAnalyzer(filePath string) *core.Analyzer {
    ext := filepath.Ext(filePath)
    
    switch ext {
    case ".go":
        return core.NewAnalyzer(
            golang.NewParser(),
            []core.Rule{golang.UnsafeRule{}},
        )
    case ".py":
        return core.NewAnalyzer(
            python.NewParser(),
            []core.Rule{python.EvalRule{}},
        )
    default:
        panic("Unsupported file type: " + ext)
    }
}


for _, rule := range a.Rules {
    issues := rule.Detect(tree)
    for i := range issues {
        issues[i].FilePath = filePath
    }
    results = append(results, issues...)
}

return results


// analyzer/core/types.go
package core

import "github.com/smacker/go-tree-sitter"

type (
    Parser interface {
        Parse([]byte) *tree_sitter.Tree
    }

    Rule interface {
        Detect(*tree_sitter.Tree) []Issue
    }

    Issue struct {
        RuleID   string
        Message  string
        Severity string
        Line     int
        Column   int
        FilePath string
    }

    Analyzer struct {
        Parser Parser
        Rules  []Rule
    }
)

// analyzer/core/analyzer.go
package core

func NewAnalyzer(p Parser, rules []Rule) *Analyzer {
    return &Analyzer{
        Parser: p,
        Rules:  rules,
    }
}

func (a *Analyzer) Analyze(code []byte, filePath string) []Issue {
    tree := a.Parser.Parse(code)
    var results []Issue
    
    for _, rule := range a.Rules {
        detected := rule.Detect(tree)
        // Add file path to issues
        for i := range detected {
            detected[i].FilePath = filePath
        }
        results = append(results, detected...)
    }
    
    return results
}


// analyzer/languages/python/rules.go
package python

import (
    "github.com/smacker/go-tree-sitter"
    "analyzer/core"
)

type EvalRule struct{}

func (r EvalRule) Detect(tree *tree_sitter.Tree) []core.Issue {
    query := `(call function: (identifier) @func (#eq? @func "eval"))`
    q, _ := tree_sitter.NewQuery([]byte(query), python.GetLanguage())
    defer q.Close()

    qc := tree_sitter.NewQueryCursor()
    defer qc.Close()
    qc.Exec(q, tree.RootNode())

    var issues []core.Issue
    for {
        match, ok := qc.NextMatch()
        if !ok {
            break
        }

        for _, capture := range match.Captures {
            if capture.Node.Type() == "identifier" {
                start := capture.Node.StartPoint()
                issues = append(issues, core.Issue{
                    RuleID:   "PYTHON_EVAL",
                    Message:  "Use of eval() function detected",
                    Severity: "HIGH",
                    Line:     int(start.Row) + 1,
                    Column:  int(start.Column) + 1,
                })
            }
        }
    }
    return issues
}


// analyzer/languages/go/rules.go
package golang

import (
    "github.com/smacker/go-tree-sitter"
    "analyzer/core"
)

type UnsafeImportRule struct{}

func (r UnsafeImportRule) Detect(tree *tree_sitter.Tree) []core.Issue {
    query := `(import_spec path: (string_lit) @path (#eq? @path "\"unsafe\""))`
    q, _ := tree_sitter.NewQuery([]byte(query), golang.GetLanguage())
    defer q.Close()

    qc := tree_sitter.NewQueryCursor()
    defer qc.Close()
    qc.Exec(q, tree.RootNode())

    var issues []core.Issue
    for {
        match, ok := qc.NextMatch()
        if !ok {
            break
        }

        for _, capture := range match.Captures {
            if capture.Node.Type() == "import_spec" {
                start := capture.Node.StartPoint()
                issues = append(issues, core.Issue{
                    RuleID:   "GO_UNSAFE",
                    Message:  "Import of unsafe package detected",
                    Severity: "MEDIUM",
                    Line:     int(start.Row) + 1,
                    Column:  int(start.Column) + 1,
                })
            }
        }
    }
    return issues
}


// analyzer/main.go
package main

import (
    "fmt"
    "os"
    "path/filepath"
    "analyzer/core"
    "analyzer/languages/golang"
    "analyzer/languages/python"
)

func main() {
    if len(os.Args) < 2 {
        fmt.Println("Usage: analyzer <file>")
        os.Exit(1)
    }

    filePath := os.Args[1]
    code, err := os.ReadFile(filePath)
    if err != nil {
        panic(err)
    }

    analyzer := createAnalyzer(filePath)
    issues := analyzer.Analyze(code, filePath)

    for _, issue := range issues {
        fmt.Printf("[%s] %s:%d:%d - %s (%s Severity)\n",
            issue.RuleID,
            issue.FilePath,
            issue.Line,
            issue.Column,
            issue.Message,
            issue.Severity,
        )
    }
}

func createAnalyzer(filePath string) *core.Analyzer {
    ext := filepath.Ext(filePath)
    
    switch ext {
    case ".go":
        return core.NewAnalyzer(
            golang.NewParser(),
            []core.Rule{golang.UnsafeImportRule{}},
        )
    case ".py":
        return core.NewAnalyzer(
            python.NewParser(),
            []core.Rule{python.EvalRule{}},
        )
    default:
        panic("Unsupported file type: " + ext)
    }
}


type UnusedVariableRule struct{}

func (r *UnusedVariableRule) ID() string       { return "GO-002" }
func (r *UnusedVariableRule) Severity() string { return "warning" }

func (r *UnusedVariableRule) Analyze(rawAST interface{}, _ core.Language) []core.Issue {
    goAST := rawAST.(struct {
        AST  *ast.File
        Fset *token.FileSet
    })
    fset := goAST.Fset

    // Track variable declarations and usages
    declared := make(map[*ast.Object]bool)
    used := make(map[*ast.Object]bool)

    ast.Inspect(goAST.AST, func(n ast.Node) bool {
        switch x := n.(type) {
        case *ast.Ident:
            if x.Obj != nil && x.Obj.Kind == ast.Var {
                if x.Obj.Decl != nil {
                    declared[x.Obj] = true // Declaration
                }
                used[x.Obj] = true // Usage
            }
        }
        return true
    })

    var issues []core.Issue
    for obj := range declared {
        if !used[obj] {
            pos := fset.Position(obj.Pos())
            issues = append(issues, core.Issue{
                RuleID:   r.ID(),
                Message:  fmt.Sprintf("Unused variable '%s'", obj.Name),
                Severity: r.Severity(),
                Line:     pos.Line,
                Column:   pos.Column,
                FilePath: pos.Filename,
            })
        }
    }
    return issues
}


type UnusedImportRule struct{}

func (r *UnusedImportRule) ID() string       { return "GO-003" }
func (r *UnusedImportRule) Severity() string { return "warning" }

func (r *UnusedImportRule) Analyze(rawAST interface{}, _ core.Language) []core.Issue {
    goAST := rawAST.(struct {
        AST  *ast.File
        Fset *token.FileSet
    })
    fset := goAST.Fset

    type importInfo struct {
        path  string
        ident string
        pos   token.Pos
    }

    var imports []importInfo

    // Collect all non-underscore/non-dot imports
    for _, decl := range goAST.AST.Decls {
        genDecl, ok := decl.(*ast.GenDecl)
        if !ok || genDecl.Tok != token.IMPORT {
            continue
        }

        for _, spec := range genDecl.Specs {
            importSpec := spec.(*ast.ImportSpec)
            path := strings.Trim(importSpec.Path.Value, `"`)

            // Skip underscore and dot imports
            if importSpec.Name != nil {
                if importSpec.Name.Name == "_" || importSpec.Name.Name == "." {
                    continue
                }
            }

            // Determine identifier to track
            ident := ""
            if importSpec.Name != nil {
                ident = importSpec.Name.Name
            } else {
                parts := strings.Split(path, "/")
                ident = parts[len(parts)-1]
            }

            imports = append(imports, importInfo{
                path:  path,
                ident: ident,
                pos:   importSpec.Pos(),
            })
        }
    }

    // Track used package identifiers
    used := make(map[string]bool)
    ast.Inspect(goAST.AST, func(n ast.Node) bool {
        if selector, ok := n.(*ast.SelectorExpr); ok {
            if xIdent, ok := selector.X.(*ast.Ident); ok {
                used[xIdent.Name] = true
            }
        }
        return true
    })

    // Generate issues for unused imports
    var issues []core.Issue
    for _, imp := range imports {
        if !used[imp.ident] {
            pos := fset.Position(imp.pos)
            issues = append(issues, core.Issue{
                RuleID:   r.ID(),
                Message:  fmt.Sprintf("Unused import '%s'", imp.path),
                Severity: r.Severity(),
                Line:     pos.Line,
                Column:   pos.Column,
                FilePath: pos.Filename,
            })
        }
    }

    return issues
}
